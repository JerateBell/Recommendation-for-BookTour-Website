"""
Hybrid Recommendation System for Travel Activities
K·∫øt h·ª£p Collaborative Filtering (CF) v√† Content-Based Filtering (CB)

Adapted from rcm/final/hybrid_cf_cb.py
- S·ª≠a ƒë·ªÉ ph√π h·ª£p v·ªõi 20 categories t·ª´ backend NestJS
- ƒê·ªçc d·ªØ li·ªáu t·ª´ CSV thay v√¨ ml-100k dataset
- Xu·∫•t k·∫øt qu·∫£ recommendation ra CSV
"""

import sys
import io
# Fix encoding for Windows terminal
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.linear_model import ElasticNet, Ridge
from scipy import sparse
from math import sqrt
import warnings
import os
import pickle
import argparse
warnings.filterwarnings('ignore')


# ============================================================================
# COLLABORATIVE FILTERING (t·ª´ cf.py)
# ============================================================================

class CF(object):
    """Base Collaborative Filtering class"""
    
    def __init__(self, Y_data, k, dist_func=cosine_similarity, uuCF=1):
        self.uuCF = uuCF
        self.Y_data = Y_data if uuCF else Y_data[:, [1, 0, 2]]
        self.k = k
        self.dist_func = dist_func
        self.Ybar_data = None
        self.n_users = int(np.max(self.Y_data[:, 0])) + 1
        self.n_items = int(np.max(self.Y_data[:, 1])) + 1
    
    def normalize_Y(self):
        users = self.Y_data[:, 0]
        self.Ybar_data = self.Y_data.copy()
        self.mu = np.zeros((self.n_users,))
        
        for n in range(self.n_users):
            ids = np.where(users == n)[0].astype(np.int32)
            ratings = self.Y_data[ids, 2]
            m = np.mean(ratings)
            if np.isnan(m):
                m = 0
            self.mu[n] = m
            self.Ybar_data[ids, 2] = ratings - self.mu[n]

        self.Ybar = sparse.coo_matrix((self.Ybar_data[:, 2],
            (self.Ybar_data[:, 1], self.Y_data[:, 0])), (self.n_items, self.n_users))
        self.Ybar = self.Ybar.tocsr()

    def similarity(self):
        self.S = self.dist_func(self.Ybar.T, self.Ybar.T)
    
    def fit(self):
        self.normalize_Y()
        self.similarity()
    
    def __pred(self, u, i, normalized=1):
        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)
        users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)
        sim = self.S[u, users_rated_i]
        a = np.argsort(sim)[-self.k:]
        nearest_s = sim[a]
        r = self.Ybar[i, users_rated_i[a]]
        if normalized:
            return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8)
        return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8) + self.mu[u]
    
    def pred(self, u, i, normalized=1):
        if self.uuCF:
            return self.__pred(u, i, normalized)
        return self.__pred(i, u, normalized)


class HybridCF:
    """K·∫øt h·ª£p User-User CF v√† Item-Item CF"""
    
    def __init__(self, Y_data, k, alpha=0.5):
        self.Y_data = Y_data
        self.k = k
        self.alpha = alpha
        self.uu_cf = CF(Y_data, k, uuCF=1)
        self.ii_cf = CF(Y_data, k, uuCF=0)
    
    def fit(self):
        self.uu_cf.fit()
        self.ii_cf.fit()
    
    def pred(self, u, i, normalized=0):
        pred_uu = self.uu_cf.pred(u, i, normalized=0)
        pred_ii = self.ii_cf.pred(u, i, normalized=0)
        return self.alpha * pred_uu + (1 - self.alpha) * pred_ii


# ============================================================================
# CONTENT-BASED FILTERING
# ============================================================================

class ContentBasedFiltering:
    """Content-Based Filtering v·ªõi ElasticNet"""
    
    def __init__(self, rate_train, tfidf, alpha=0.01, l1_ratio=0.5):
        self.rate_train = rate_train
        self.tfidf = tfidf
        self.alpha = alpha
        self.l1_ratio = l1_ratio
        self.W = None
        self.b = None
        self.n_users = int(np.max(rate_train[:, 0])) + 1
        self.d = tfidf.shape[1]
    
    def get_items_rated_by_user(self, rate_matrix, user_id):
        """return (item_ids, scores)"""
        y = rate_matrix[:, 0]
        ids = np.where(y == user_id)[0]
        item_ids = rate_matrix[ids, 1]
        scores = rate_matrix[ids, 2]
        return (item_ids, scores)
    
    def fit(self):
        """Train ElasticNet model cho t·ª´ng user"""
        global_mean = np.mean(self.rate_train[:, 2])
        MIN_RATINGS = 5
        
        self.W = np.zeros((self.d, self.n_users))
        self.b = np.zeros((1, self.n_users))
        
        print(f"  üîß Training Content-Based models cho {self.n_users} users...")
        for n in range(self.n_users):
            ids, scores = self.get_items_rated_by_user(self.rate_train, n)
            
            if len(ids) < MIN_RATINGS:
                self.b[0, n] = global_mean
                self.W[:, n] = 0
                continue
            
            Xhat = self.tfidf[ids, :]
            clf = ElasticNet(alpha=self.alpha, l1_ratio=self.l1_ratio, 
                            fit_intercept=True, max_iter=1000)
            try:
                clf.fit(Xhat, scores)
                self.W[:, n] = clf.coef_
                self.b[0, n] = clf.intercept_
            except:
                clf_fallback = Ridge(alpha=0.1, fit_intercept=True)
                clf_fallback.fit(Xhat, scores)
                self.W[:, n] = clf_fallback.coef_
                self.b[0, n] = clf_fallback.intercept_
            
            if (n + 1) % 100 == 0:
                print(f"    Processed {n+1}/{self.n_users} users...")
        
        print("  ‚úÖ Content-Based training completed!")
    
    def pred(self, u, i):
        """D·ª± ƒëo√°n rating c·ªßa user u cho item i"""
        if self.W is None or self.b is None:
            raise ValueError("Model ch∆∞a ƒë∆∞·ª£c train. G·ªçi fit() tr∆∞·ªõc.")
        
        # Yhat[i, u] = tfidf[i, :] √ó W[:, u] + b[u]
        pred = self.tfidf[i, :].dot(self.W[:, u]) + self.b[0, u]
        return pred


# ============================================================================
# HYBRID SYSTEM: CF + Content-Based
# ============================================================================

class HybridCFCB:
    """
    K·∫øt h·ª£p Collaborative Filtering v√† Content-Based Filtering
    """
    
    def __init__(self, rate_train, tfidf, cf_k=30, cf_alpha=0.5, 
                 cb_alpha=0.01, cb_l1_ratio=0.5, weight_cf=0.5):
        """
        Parameters:
        - rate_train: training ratings data
        - tfidf: TF-IDF matrix c·ªßa items
        - cf_k: s·ªë neighbors cho CF
        - cf_alpha: tr·ªçng s·ªë User-User vs Item-Item CF
        - cb_alpha: alpha cho ElasticNet trong Content-Based
        - cb_l1_ratio: l1_ratio cho ElasticNet
        - weight_cf: tr·ªçng s·ªë cho CF (weight_cb = 1 - weight_cf)
        """
        self.rate_train = rate_train
        self.tfidf = tfidf
        self.weight_cf = weight_cf
        self.weight_cb = 1 - weight_cf
        
        # Kh·ªüi t·∫°o 2 models
        print("üì¶ Kh·ªüi t·∫°o models...")
        print(f"  - Collaborative Filtering (k={cf_k}, alpha={cf_alpha})")
        print(f"  - Content-Based Filtering (alpha={cb_alpha}, l1_ratio={cb_l1_ratio})")
        print(f"  - Ensemble weights: CF={weight_cf:.2f}, CB={self.weight_cb:.2f}")
        
        self.cf_model = HybridCF(rate_train, k=cf_k, alpha=cf_alpha)
        self.cb_model = ContentBasedFiltering(rate_train, tfidf, 
                                             alpha=cb_alpha, l1_ratio=cb_l1_ratio)
    
    def fit(self):
        """Train c·∫£ 2 models"""
        print("\nüîß Training Collaborative Filtering...")
        self.cf_model.fit()
        
        print("\nüîß Training Content-Based Filtering...")
        self.cb_model.fit()
        
        print("\n‚úÖ T·∫•t c·∫£ models ƒë√£ ƒë∆∞·ª£c train xong!")
    
    def pred(self, u, i):
        """
        D·ª± ƒëo√°n rating b·∫±ng c√°ch k·∫øt h·ª£p CF v√† Content-Based
        """
        try:
            # Prediction t·ª´ CF
            pred_cf = self.cf_model.pred(u, i, normalized=0)
            pred_cf = np.clip(pred_cf, 1, 5)  # Clip trong [1, 5]
        except:
            pred_cf = 3.0  # Default value
        
        try:
            # Prediction t·ª´ Content-Based
            pred_cb = self.cb_model.pred(u, i)
            pred_cb = np.clip(pred_cb, 1, 5)  # Clip trong [1, 5]
        except:
            pred_cb = 3.0  # Default value
        
        # Weighted ensemble
        pred_hybrid = self.weight_cf * pred_cf + self.weight_cb * pred_cb
        
        return pred_hybrid
    
    def recommend(self, u, n_items, top_n=10):
        """Recommend top N items cho user u"""
        # T√¨m c√°c items m√† user ch∆∞a rate
        ids = np.where(self.rate_train[:, 0] == u)[0]
        items_rated_by_u = self.rate_train[ids, 1].tolist()
        
        predictions = []
        
        for i in range(n_items):
            if i not in items_rated_by_u:
                try:
                    rating = self.pred(u, i)
                    predictions.append((i, rating))
                except:
                    continue
        
        # Sort theo rating gi·∫£m d·∫ßn
        predictions.sort(key=lambda x: x[1], reverse=True)
        
        return predictions[:top_n]


# ============================================================================
# DATA LOADING & PROCESSING
# ============================================================================

def load_ratings_from_csv(file_path):
    """
    Load ratings t·ª´ CSV file (format: user_id, activity_id, rating, timestamp)
    """
    print(f"üìÇ ƒêang load ratings t·ª´ {file_path}...")
    
    try:
        # ƒê·ªçc CSV (tab-separated ho·∫∑c comma-separated)
        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path, sep=',', header=0)
        else:
            # Format ml-100k (tab-separated, no header)
            df = pd.read_csv(file_path, sep='\t', header=None, 
                           names=['user_id', 'activity_id', 'rating', 'timestamp'])
        
        # Chuy·ªÉn ƒë·ªïi sang numpy array (user_id, activity_id, rating)
        ratings = df[['user_id', 'activity_id', 'rating']].to_numpy()
        
        # ƒê·∫£m b·∫£o IDs b·∫Øt ƒë·∫ßu t·ª´ 0
        ratings[:, 0] = ratings[:, 0] - 1  # user_id: 1-based -> 0-based
        ratings[:, 1] = ratings[:, 1] - 1  # activity_id: 1-based -> 0-based
        
        print(f"‚úÖ ƒê√£ load {ratings.shape[0]} ratings")
        return ratings
        
    except Exception as e:
        print(f"‚ùå L·ªói khi load ratings: {e}")
        raise


def load_activities_from_csv(file_path):
    """
    Load activities t·ª´ CSV file
    Format t·ª´ backend: activity_id, category_id, cat0, cat1, ..., cat19
    (T·ªïng c·ªông 22 c·ªôt: activity_id, category_id, v√† 20 binary category columns)
    """
    print(f"üìÇ ƒêang load activities t·ª´ {file_path}...")
    
    try:
        df = pd.read_csv(file_path, sep=',', header=0)
        
        # L·∫•y activity_id (c·ªôt ƒë·∫ßu ti√™n)
        activity_ids = df.iloc[:, 0].values
        
        # Format t·ª´ backend: activity_id, category_id, cat0, cat1, ..., cat19
        # B·ªè 2 c·ªôt ƒë·∫ßu (activity_id, category_id), l·∫•y 20 c·ªôt binary ti·∫øp theo
        if df.shape[1] >= 22:
            # L·∫•y 20 c·ªôt binary t·ª´ c·ªôt index 2-21 (cat0 ƒë·∫øn cat19)
            category_features = df.iloc[:, 2:22].values.astype(float)
        elif df.shape[1] == 2 and 'category_id' in df.columns:
            # N·∫øu ch·ªâ c√≥ activity_id v√† category_id, chuy·ªÉn sang one-hot encoding
            category_id = df['category_id'].values
            n_categories = 20
            category_features = np.zeros((len(category_id), n_categories))
            for i, cat_id in enumerate(category_id):
                cat_idx = int(cat_id) if not np.isnan(cat_id) else 0
                if 0 <= cat_idx < n_categories:
                    category_features[i, cat_idx] = 1
        else:
            raise ValueError(f"Format CSV kh√¥ng h·ª£p l·ªá. Expected 22 columns, got {df.shape[1]}")
        
        print(f"‚úÖ ƒê√£ load {len(activity_ids)} activities v·ªõi {category_features.shape[1]} category features")
        return activity_ids, category_features
        
    except Exception as e:
        print(f"‚ùå L·ªói khi load activities: {e}")
        raise


def create_tfidf_features(category_features):
    """
    T·∫°o TF-IDF features t·ª´ category binary matrix
    V√¨ l√† binary features n√™n TF-IDF s·∫Ω kh√¥ng thay ƒë·ªïi nhi·ªÅu, nh∆∞ng v·∫´n √°p d·ª•ng ƒë·ªÉ chu·∫©n h√≥a
    """
    print("üîß ƒêang t·∫°o TF-IDF features...")
    
    # √Åp d·ª•ng TF-IDF transformation
    transformer = TfidfTransformer(smooth_idf=True, norm='l2')
    tfidf = transformer.fit_transform(category_features).toarray()
    
    print(f"‚úÖ TF-IDF shape: {tfidf.shape}")
    return tfidf


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    # Parse command line arguments
    parser = argparse.ArgumentParser(description='Hybrid Recommendation System')
    parser.add_argument('--retrain', action='store_true', 
                       help='Train l·∫°i model t·ª´ ƒë·∫ßu (b·ªè qua cache)')
    parser.add_argument('--ratings', type=str, default='ratings.csv',
                       help='Path to ratings CSV file (default: ratings.csv)')
    parser.add_argument('--activities', type=str, default='activities.csv',
                       help='Path to activities CSV file (default: activities.csv)')
    parser.add_argument('--output', type=str, default='recommendations.csv',
                       help='Path to output CSV file (default: recommendations.csv)')
    
    args = parser.parse_args()
    
    print("\n" + "="*70)
    print("HYBRID RECOMMENDATION SYSTEM FOR TRAVEL ACTIVITIES")
    print("K·∫øt h·ª£p Collaborative Filtering + Content-Based Filtering")
    print("="*70)
    
    # ========================================================================
    # Load data t·ª´ CSV files
    # ========================================================================
    ratings_file = args.ratings
    activities_file = args.activities
    output_file = args.output
    force_retrain = args.retrain
    
    # Ki·ªÉm tra files c√≥ t·ªìn t·∫°i kh√¥ng
    if not os.path.exists(ratings_file):
        print(f"\n‚ùå Kh√¥ng t√¨m th·∫•y file {ratings_file}")
        print("   Vui l√≤ng ƒë·∫£m b·∫£o file ratings.csv c√≥ trong c√πng th∆∞ m·ª•c")
        return
    
    if not os.path.exists(activities_file):
        print(f"\n‚ùå Kh√¥ng t√¨m th·∫•y file {activities_file}")
        print("   Vui l√≤ng ƒë·∫£m b·∫£o file activities.csv c√≥ trong c√πng th∆∞ m·ª•c")
        return
    
    # Load activities v√† category features TR∆Ø·ªöC ƒë·ªÉ bi·∫øt activity IDs h·ª£p l·ªá
    activity_ids, category_features = load_activities_from_csv(activities_file)
    
    # Load v√† filter ratings: ch·ªâ gi·ªØ ratings cho activities c√≤n t·ªìn t·∫°i
    print(f"\nüîç ƒêang l·ªçc v√† map ratings ƒë·ªÉ kh·ªõp v·ªõi {len(activity_ids)} activities h·ª£p l·ªá...")
    
    # Load l·∫°i ratings t·ª´ CSV ƒë·ªÉ filter tr∆∞·ªõc khi convert
    df_ratings_original = pd.read_csv(ratings_file, sep=',', header=0)
    valid_activity_ids_set = set([int(aid) for aid in activity_ids])
    
    # Filter ratings: ch·ªâ gi·ªØ ratings c√≥ activity_id trong danh s√°ch activities h·ª£p l·ªá
    original_ratings_count = len(df_ratings_original)
    df_ratings_filtered = df_ratings_original[df_ratings_original['activity_id'].isin(valid_activity_ids_set)].copy()
    
    if len(df_ratings_filtered) < original_ratings_count:
        removed_count = original_ratings_count - len(df_ratings_filtered)
        print(f"   ‚ö†Ô∏è  ƒê√£ lo·∫°i b·ªè {removed_count} ratings cho activities kh√¥ng t·ªìn t·∫°i")
    
    if len(df_ratings_filtered) == 0:
        print(f"\n‚ùå Kh√¥ng c√≤n ratings h·ª£p l·ªá n√†o sau khi l·ªçc!")
        print(f"   Ki·ªÉm tra l·∫°i file ratings.csv v√† activities.csv")
        return
    
    # T·∫°o mapping t·ª´ activity_id th·ª±c t·∫ø (t·ª´ CSV) sang index (0-based) trong activity_ids array
    activity_id_to_index_map = {int(activity_ids[i]): i for i in range(len(activity_ids))}
    
    # Map activity_id t·ª´ ID th·ª±c t·∫ø sang index (0-based)
    df_ratings_filtered['activity_id'] = df_ratings_filtered['activity_id'].map(activity_id_to_index_map)
    
    # Remove any rows where activity_id mapping failed (shouldn't happen after filter, but just in case)
    df_ratings_filtered = df_ratings_filtered.dropna(subset=['activity_id'])
    
    # Convert sang numpy array
    rate_train = df_ratings_filtered[['user_id', 'activity_id', 'rating']].to_numpy()
    
    # Convert user_id sang 0-based
    rate_train[:, 0] = rate_train[:, 0] - 1
    
    # Convert activity_id sang int (ƒë√£ l√† index 0-based)
    rate_train[:, 1] = rate_train[:, 1].astype(int)
    
    print(f"   ‚úÖ C√≤n l·∫°i {len(rate_train)} ratings h·ª£p l·ªá sau khi l·ªçc v√† map")
    
    # T·∫°o TF-IDF features
    tfidf = create_tfidf_features(category_features)
    
    # ========================================================================
    # Load ho·∫∑c Train Hybrid Model
    # ========================================================================
    print("\n" + "="*70)
    print("üîß LOADING/TRAINING HYBRID MODEL")
    print("="*70)
    
    # T·∫°o cache file name d·ª±a tr√™n config
    model_cache_file = 'hybrid_model_cache.pkl'
    
    # Ki·ªÉm tra cache v√† load n·∫øu c√≥ (tr·ª´ khi force retrain)
    hybrid_model = None
    
    if not force_retrain and os.path.exists(model_cache_file):
        print(f"üì¶ T√¨m th·∫•y model ƒë√£ train s·∫µn: {model_cache_file}")
        print("   ƒêang load model t·ª´ cache...")
        print("   (ƒê·ªÉ train l·∫°i model, s·ª≠ d·ª•ng flag --retrain)")
        
        try:
            with open(model_cache_file, 'rb') as f:
                cache_data = pickle.load(f)
            
            hybrid_model = cache_data.get('model')
            
            if hybrid_model:
                cached_info = cache_data.get('info', {})
                print(f"   ‚úÖ ƒê√£ load model t·ª´ cache th√†nh c√¥ng!")
                if cached_info:
                    print(f"      - S·ªë users khi train: {cached_info.get('n_users', 'N/A')}")
                    print(f"      - S·ªë activities khi train: {cached_info.get('n_items', 'N/A')}")
                
                # Update model v·ªõi d·ªØ li·ªáu m·ªõi (ratings v√† activities m·ªõi)
                print(f"   üîÑ ƒêang c·∫≠p nh·∫≠t model v·ªõi d·ªØ li·ªáu m·ªõi...")
                hybrid_model.rate_train = rate_train
                hybrid_model.tfidf = tfidf
                # Update trong c√°c sub-models n·∫øu c·∫ßn
                if hasattr(hybrid_model, 'cf_model'):
                    hybrid_model.cf_model.Y_data = rate_train
                if hasattr(hybrid_model, 'cb_model'):
                    hybrid_model.cb_model.rate_train = rate_train
                    hybrid_model.cb_model.tfidf = tfidf
                print(f"      ‚úÖ ƒê√£ c·∫≠p nh·∫≠t v·ªõi d·ªØ li·ªáu m·ªõi")
            else:
                print(f"   ‚ö†Ô∏è  Cache file kh√¥ng h·ª£p l·ªá, s·∫Ω train l·∫°i...")
                hybrid_model = None
        except Exception as e:
            print(f"   ‚ö†Ô∏è  L·ªói khi load cache: {e}")
            print(f"      S·∫Ω train l·∫°i model m·ªõi...")
            hybrid_model = None
    elif force_retrain:
        print("   üîÑ Flag --retrain ƒë∆∞·ª£c b·∫≠t, s·∫Ω train l·∫°i model t·ª´ ƒë·∫ßu...")
    else:
        print("   üì≠ Kh√¥ng t√¨m th·∫•y model cache, s·∫Ω train model m·ªõi...")
    
    # Train model n·∫øu ch∆∞a c√≥ ho·∫∑c force retrain
    if hybrid_model is None:
        print("\n   üîß B·∫Øt ƒë·∫ßu train model m·ªõi...")
        
        # S·ª≠ d·ª•ng tr·ªçng s·ªë ƒë√£ t·ªëi ∆∞u (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh)
        weight_cf = 0.5  # C√≥ th·ªÉ th·ª≠ c√°c gi√° tr·ªã kh√°c: 0.25, 0.5, 0.75
        
        hybrid_model = HybridCFCB(
            rate_train, 
            tfidf,
            cf_k=30, 
            cf_alpha=0.5,
            cb_alpha=0.01, 
            cb_l1_ratio=0.5,
            weight_cf=weight_cf
        )
        
        hybrid_model.fit()
        
        # L∆∞u model v√†o cache
        print(f"\nüíæ ƒêang l∆∞u model v√†o cache: {model_cache_file}...")
        try:
            cache_data = {
                'model': hybrid_model,
                'info': {
                    'n_users': int(np.max(rate_train[:, 0])) + 1,
                    'n_items': len(activity_ids),
                }
            }
            with open(model_cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
            print(f"   ‚úÖ ƒê√£ l∆∞u model v√†o cache th√†nh c√¥ng!")
            print(f"      L·∫ßn ch·∫°y sau s·∫Ω t·ª± ƒë·ªông d√πng model n√†y (kh√¥ng c·∫ßn train l·∫°i)")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Kh√¥ng th·ªÉ l∆∞u cache: {e}")
            print(f"      L·∫ßn ch·∫°y sau s·∫Ω ph·∫£i train l·∫°i.")
    
    # ========================================================================
    # Generate Recommendations cho t·∫•t c·∫£ users
    # ========================================================================
    print("\n" + "="*70)
    print("üéØ GENERATING RECOMMENDATIONS")
    print("="*70)
    
    n_users = int(np.max(rate_train[:, 0])) + 1
    n_items = len(activity_ids)
    
    print(f"\nüìä T·ªïng s·ªë users: {n_users}")
    print(f"üìä T·ªïng s·ªë activities: {n_items}")
    print(f"üìä S·∫Ω recommend top 10 activities cho m·ªói user...")
    
    all_recommendations = []
    
    for user_id in range(n_users):
        recommendations = hybrid_model.recommend(user_id, n_items, top_n=10)
        
        for activity_idx, predicted_rating in recommendations:
            # Chuy·ªÉn ƒë·ªïi l·∫°i index v·ªÅ activity_id th·ª±c t·∫ø
            actual_activity_id = activity_ids[int(activity_idx)]
            actual_user_id = user_id + 1  # Chuy·ªÉn v·ªÅ 1-based
            
            all_recommendations.append({
                'user_id': int(actual_user_id),
                'activity_id': int(actual_activity_id),
                'predicted_rating': float(predicted_rating)
            })
        
        if (user_id + 1) % 50 == 0:
            print(f"  Processed {user_id + 1}/{n_users} users...")
    
    # ========================================================================
    # L∆∞u k·∫øt qu·∫£ ra CSV
    # ========================================================================
    print(f"\nüíæ ƒêang l∆∞u recommendations v√†o {output_file}...")
    
    df_recommendations = pd.DataFrame(all_recommendations)
    df_recommendations = df_recommendations.sort_values(['user_id', 'predicted_rating'], 
                                                        ascending=[True, False])
    
    # L∆∞u ra CSV
    df_recommendations.to_csv(output_file, index=False, sep=',')
    
    print(f"‚úÖ ƒê√£ l∆∞u {len(all_recommendations)} recommendations v√†o {output_file}")
    print(f"   Format: user_id, activity_id, predicted_rating")
    
    # Hi·ªÉn th·ªã th·ªëng k√™
    print("\n" + "="*70)
    print("üìä TH·ªêNG K√ä")
    print("="*70)
    print(f"   T·ªïng s·ªë recommendations: {len(all_recommendations)}")
    print(f"   S·ªë users: {n_users}")
    print(f"   Trung b√¨nh recommendations/user: {len(all_recommendations) / n_users:.1f}")
    print(f"   Rating d·ª± ƒëo√°n trung b√¨nh: {df_recommendations['predicted_rating'].mean():.2f}")
    print(f"   Rating d·ª± ƒëo√°n cao nh·∫•t: {df_recommendations['predicted_rating'].max():.2f}")
    print(f"   Rating d·ª± ƒëo√°n th·∫•p nh·∫•t: {df_recommendations['predicted_rating'].min():.2f}")
    
    print("\n" + "="*70)
    print("‚úÖ HO√ÄN TH√ÄNH!")
    print("="*70)
    print(f"\nüí° File k·∫øt qu·∫£: {output_file}")
    print(f"   Backend NestJS c√≥ th·ªÉ ƒë·ªçc file n√†y ƒë·ªÉ import v√†o database")


if __name__ == "__main__":
    main()

