"""
Collaborative Filtering - Ensemble c·ªßa 4 ph∆∞∆°ng ph√°p t·ªët nh·∫•t
K·∫øt h·ª£p: Hybrid CF, CF Z-score, CF Confidence, CF Adjusted Cosine
"""

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from scipy import sparse
import warnings
warnings.filterwarnings('ignore')


# ============================================================================
# BASE CLASS - CF G·ªëc
# ============================================================================

class CF(object):
    """Base Collaborative Filtering class"""
    
    def __init__(self, Y_data, k, dist_func=cosine_similarity, uuCF=1):
        self.uuCF = uuCF
        self.Y_data = Y_data if uuCF else Y_data[:, [1, 0, 2]]
        self.k = k
        self.dist_func = dist_func
        self.Ybar_data = None
        self.n_users = int(np.max(self.Y_data[:, 0])) + 1
        self.n_items = int(np.max(self.Y_data[:, 1])) + 1
    
    def normalize_Y(self):
        users = self.Y_data[:, 0]
        self.Ybar_data = self.Y_data.copy()
        self.mu = np.zeros((self.n_users,))
        
        for n in range(self.n_users):
            ids = np.where(users == n)[0].astype(np.int32)
            ratings = self.Y_data[ids, 2]
            m = np.mean(ratings)
            if np.isnan(m):
                m = 0
            self.mu[n] = m
            self.Ybar_data[ids, 2] = ratings - self.mu[n]

        self.Ybar = sparse.coo_matrix((self.Ybar_data[:, 2],
            (self.Ybar_data[:, 1], self.Ybar_data[:, 0])), (self.n_items, self.n_users))
        self.Ybar = self.Ybar.tocsr()

    def similarity(self):
        self.S = self.dist_func(self.Ybar.T, self.Ybar.T)
    
    def fit(self):
        self.normalize_Y()
        self.similarity()
    
    def __pred(self, u, i, normalized=1):
        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)
        users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)
        sim = self.S[u, users_rated_i]
        a = np.argsort(sim)[-self.k:]
        nearest_s = sim[a]
        r = self.Ybar[i, users_rated_i[a]]
        if normalized:
            return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8)
        return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8) + self.mu[u]
    
    def pred(self, u, i, normalized=1):
        if self.uuCF:
            return self.__pred(u, i, normalized)
        return self.__pred(i, u, normalized)


# ============================================================================
# METHOD 1: Hybrid CF (User-User + Item-Item)
# ============================================================================

class HybridCF:
    """K·∫øt h·ª£p User-User CF v√† Item-Item CF"""
    
    def __init__(self, Y_data, k, alpha=0.5):
        self.Y_data = Y_data
        self.k = k
        self.alpha = alpha  # Tr·ªçng s·ªë cho User-User CF
        self.uu_cf = CF(Y_data, k, uuCF=1)
        self.ii_cf = CF(Y_data, k, uuCF=0)
    
    def fit(self):
        self.uu_cf.fit()
        self.ii_cf.fit()
    
    def pred(self, u, i, normalized=0):
        pred_uu = self.uu_cf.pred(u, i, normalized=0)
        pred_ii = self.ii_cf.pred(u, i, normalized=0)
        return self.alpha * pred_uu + (1 - self.alpha) * pred_ii


# ============================================================================
# METHOD 2: CF with Z-score Normalization
# ============================================================================

class CF_Zscore(CF):
    """CF v·ªõi Z-score normalization thay v√¨ mean-centering"""
    
    def normalize_Y(self):
        users = self.Y_data[:, 0]
        self.Ybar_data = self.Y_data.copy()
        self.mu = np.zeros((self.n_users,))
        self.sigma = np.zeros((self.n_users,))
        
        for n in range(self.n_users):
            ids = np.where(users == n)[0].astype(np.int32)
            ratings = self.Y_data[ids, 2]
            
            self.mu[n] = np.mean(ratings)
            self.sigma[n] = np.std(ratings)
            
            if self.sigma[n] > 0:
                self.Ybar_data[ids, 2] = (ratings - self.mu[n]) / self.sigma[n]
            else:
                self.Ybar_data[ids, 2] = ratings - self.mu[n]
        
        self.Ybar = sparse.coo_matrix((self.Ybar_data[:, 2],
            (self.Ybar_data[:, 1], self.Ybar_data[:, 0])), (self.n_items, self.n_users))
        self.Ybar = self.Ybar.tocsr()
    
    def __pred(self, u, i, normalized=1):
        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)
        users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)
        sim = self.S[u, users_rated_i]
        a = np.argsort(sim)[-self.k:]
        nearest_s = sim[a]
        r = self.Ybar[i, users_rated_i[a]]
        
        pred_normalized = (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8)
        
        if normalized:
            return pred_normalized
        
        # Denormalize v·ªõi sigma
        if self.sigma[u] > 0:
            return pred_normalized * self.sigma[u] + self.mu[u]
        else:
            return pred_normalized + self.mu[u]
    
    def pred(self, u, i, normalized=0):
        if self.uuCF:
            return self.__pred(u, i, normalized)
        return self.__pred(i, u, normalized)


# ============================================================================
# METHOD 3: CF with Confidence Weighting
# ============================================================================

class CF_Confidence(CF):
    """CF v·ªõi confidence weighting d·ª±a tr√™n s·ªë l∆∞·ª£ng ratings c·ªßa neighbors"""
    
    def __pred(self, u, i, normalized=1):
        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)
        users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)
        sim = self.S[u, users_rated_i]
        a = np.argsort(sim)[-self.k:]
        nearest_s = sim[a]
        
        # T√≠nh confidence d·ª±a tr√™n s·ªë ratings c·ªßa neighbors
        confidence = []
        for neighbor in users_rated_i[a]:
            n_ratings = np.sum(self.Y_data[:, 0] == neighbor)
            confidence.append(min(n_ratings / 50, 1))  # Cap at 50 ratings
        
        confidence = np.array(confidence)
        weighted_sim = nearest_s * confidence
        
        r = self.Ybar[i, users_rated_i[a]]
        
        if normalized:
            return (r * weighted_sim)[0] / (np.abs(weighted_sim).sum() + 1e-8)
        return (r * weighted_sim)[0] / (np.abs(weighted_sim).sum() + 1e-8) + self.mu[u]
    
    def pred(self, u, i, normalized=0):
        if self.uuCF:
            return self.__pred(u, i, normalized)
        return self.__pred(i, u, normalized)


# ============================================================================
# METHOD 4: CF with Adjusted Cosine Similarity
# ============================================================================

class CF_AdjustedCosine(CF):
    """CF v·ªõi adjusted cosine similarity (c√≥ tr·ªçng s·ªë theo s·ªë items chung)"""
    
    def similarity(self):
        # T√≠nh cosine similarity c∆° b·∫£n
        base_sim = cosine_similarity(self.Ybar.T, self.Ybar.T)
        
        # T√≠nh s·ªë items chung
        binary_matrix = (self.Ybar.T != 0).astype(float).toarray()
        common_items = binary_matrix @ binary_matrix.T
        
        # ƒêi·ªÅu ch·ªânh similarity d·ª±a tr√™n s·ªë items chung
        threshold = 5  # C·∫ßn √≠t nh·∫•t 5 items chung
        weight = np.minimum(common_items / threshold, 1)
        
        self.S = base_sim * weight


# ============================================================================
# ENSEMBLE MODEL - K·∫øt h·ª£p 4 ph∆∞∆°ng ph√°p t·ªët nh·∫•t
# ============================================================================

class EnsembleCF:
    """
    Ensemble c·ªßa 4 ph∆∞∆°ng ph√°p CF t·ªët nh·∫•t
    K·∫øt h·ª£p: Hybrid CF, CF Z-score, CF Confidence, CF Adjusted Cosine
    """
    
    def __init__(self, Y_data, k=30, weights=None):
        """
        Parameters:
        - Y_data: training data
        - k: s·ªë neighbors
        - weights: tr·ªçng s·ªë cho t·ª´ng model [w1, w2, w3, w4]
                   M·∫∑c ƒë·ªãnh l√† tr·ªçng s·ªë ƒë·ªÅu [0.25, 0.25, 0.25, 0.25]
        """
        self.Y_data = Y_data
        self.k = k
        
        # N·∫øu kh√¥ng cung c·∫•p weights, d√πng tr·ªçng s·ªë ƒë·ªÅu
        if weights is None:
            self.weights = [0.25, 0.25, 0.25, 0.25]
        else:
            # Normalize weights
            total = sum(weights)
            self.weights = [w/total for w in weights]
        
        # Kh·ªüi t·∫°o 4 models
        print("  üì¶ Kh·ªüi t·∫°o 4 models...")
        self.model1 = HybridCF(Y_data, k=k, alpha=0.5)
        self.model2 = CF_Zscore(Y_data, k=k, uuCF=1)
        self.model3 = CF_Confidence(Y_data, k=k, uuCF=1)
        self.model4 = CF_AdjustedCosine(Y_data, k=k, uuCF=1)
    
    def fit(self):
        """Train t·∫•t c·∫£ c√°c models"""
        print("  üîß Training Model 1: Hybrid CF...")
        self.model1.fit()
        
        print("  üîß Training Model 2: CF Z-score...")
        self.model2.fit()
        
        print("  üîß Training Model 3: CF Confidence...")
        self.model3.fit()
        
        print("  üîß Training Model 4: CF Adjusted Cosine...")
        self.model4.fit()
        
        print("  ‚úÖ T·∫•t c·∫£ models ƒë√£ ƒë∆∞·ª£c train xong!")
    
    def pred(self, u, i, normalized=0):
        """
        D·ª± ƒëo√°n rating b·∫±ng c√°ch k·∫øt h·ª£p 4 models v·ªõi tr·ªçng s·ªë
        """
        try:
            pred1 = self.model1.pred(u, i, normalized=0)
            pred2 = self.model2.pred(u, i, normalized=0)
            pred3 = self.model3.pred(u, i, normalized=0)
            pred4 = self.model4.pred(u, i, normalized=0)
            
            # Weighted average
            ensemble_pred = (self.weights[0] * pred1 + 
                           self.weights[1] * pred2 + 
                           self.weights[2] * pred3 + 
                           self.weights[3] * pred4)
            
            return ensemble_pred
        except:
            # N·∫øu c√≥ l·ªói, tr·∫£ v·ªÅ gi√° tr·ªã m·∫∑c ƒë·ªãnh
            return 3.0
    
    def recommend(self, u, top_n=10):
        """
        Recommend top N items cho user u
        """
        # T√¨m c√°c items m√† user ch∆∞a rate
        ids = np.where(self.Y_data[:, 0] == u)[0]
        items_rated_by_u = self.Y_data[ids, 1].tolist()
        
        predictions = []
        n_items = int(np.max(self.Y_data[:, 1])) + 1
        
        for i in range(n_items):
            if i not in items_rated_by_u:
                rating = self.pred(u, i)
                predictions.append((i, rating))
        
        # Sort theo rating gi·∫£m d·∫ßn
        predictions.sort(key=lambda x: x[1], reverse=True)
        
        return predictions[:top_n]


# ============================================================================
# EVALUATION FUNCTION
# ============================================================================

def evaluate_rmse(model, rate_test):
    """T√≠nh RMSE cho model"""
    n_tests = rate_test.shape[0]
    SE = 0
    
    print("  üìä ƒêang evaluate tr√™n test set...")
    for n in range(n_tests):
        try:
            pred = model.pred(int(rate_test[n, 0]), int(rate_test[n, 1]), normalized=0)
            # Clip prediction trong kho·∫£ng [1, 5]
            pred = np.clip(pred, 1, 5)
            SE += (pred - rate_test[n, 2])**2
        except:
            # N·∫øu c√≥ l·ªói, d√πng gi√° tr·ªã default
            SE += (3.0 - rate_test[n, 2])**2
        
        # Progress indicator
        if (n + 1) % 5000 == 0:
            print(f"    Processed {n+1}/{n_tests} samples...")
    
    return np.sqrt(SE / n_tests)


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    print("\n" + "="*70)
    print("ENSEMBLE CF - K·∫æT H·ª¢P 4 PH∆Ø∆†NG PH√ÅP T·ªêT NH·∫§T")
    print("="*70)
    
    # Load data
    print("\nüìÇ ƒêang load MovieLens 100k dataset...")
    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']
    
    try:
        ratings_base = pd.read_csv('ml-100k/ub.base', sep='\t', names=r_cols, encoding='latin-1')
        ratings_test = pd.read_csv('ml-100k/ub.test', sep='\t', names=r_cols, encoding='latin-1')
    except:
        print("‚ùå Kh√¥ng t√¨m th·∫•y file dataset!")
        print("   Vui l√≤ng t·∫£i MovieLens 100k v√† ƒë·∫∑t trong folder 'ml-100k/'")
        return
    
    rate_train = ratings_base.to_numpy()
    rate_test = ratings_test.to_numpy()
    
    # Indices start from 0
    rate_train[:, :2] -= 1
    rate_test[:, :2] -= 1
    
    print(f"‚úÖ Dataset loaded: {rate_train.shape[0]} training, {rate_test.shape[0]} test samples")
    
    # ========================================================================
    # So s√°nh c√°c c·∫•u h√¨nh tr·ªçng s·ªë kh√°c nhau
    # ========================================================================
    
    weight_configs = {
        "Tr·ªçng s·ªë ƒë·ªÅu": [0.25, 0.25, 0.25, 0.25],
        "∆Øu ti√™n Hybrid CF": [0.5, 0.2, 0.2, 0.1],
        "∆Øu ti√™n top 3": [0.4, 0.3, 0.3, 0.0],
        "T·ªëi ∆∞u theo k·∫øt qu·∫£": [0.35, 0.30, 0.25, 0.10],  # D·ª±a tr√™n RMSE ƒë√£ c√≥
    }
    
    results = {}
    
    for config_name, weights in weight_configs.items():
        print("\n" + "-"*70)
        print(f"üîπ Testing: {config_name}")
        print(f"   Weights: {weights}")
        print("-"*70)
        
        # T·∫°o v√† train ensemble model
        ensemble = EnsembleCF(rate_train, k=30, weights=weights)
        ensemble.fit()
        
        # Evaluate
        rmse = evaluate_rmse(ensemble, rate_test)
        results[config_name] = rmse
        print(f"  ‚úÖ RMSE = {rmse:.4f}")
    
    # ========================================================================
    # So s√°nh v·ªõi t·ª´ng model ri√™ng l·∫ª
    # ========================================================================
    
    print("\n" + "="*70)
    print("üìä SO S√ÅNH V·ªöI C√ÅC MODEL RI√äNG L·∫∫")
    print("="*70)
    
    # Model 1: Hybrid CF
    print("\nüîπ Model 1: Hybrid CF")
    model1 = HybridCF(rate_train, k=30, alpha=0.5)
    model1.fit()
    rmse1 = evaluate_rmse(model1, rate_test)
    results['Hybrid CF (ri√™ng)'] = rmse1
    print(f"  RMSE = {rmse1:.4f}")
    
    # Model 2: CF Z-score
    print("\nüîπ Model 2: CF Z-score")
    model2 = CF_Zscore(rate_train, k=30, uuCF=1)
    model2.fit()
    rmse2 = evaluate_rmse(model2, rate_test)
    results['CF Z-score (ri√™ng)'] = rmse2
    print(f"  RMSE = {rmse2:.4f}")
    
    # Model 3: CF Confidence
    print("\nüîπ Model 3: CF Confidence")
    model3 = CF_Confidence(rate_train, k=30, uuCF=1)
    model3.fit()
    rmse3 = evaluate_rmse(model3, rate_test)
    results['CF Confidence (ri√™ng)'] = rmse3
    print(f"  RMSE = {rmse3:.4f}")
    
    # Model 4: CF Adjusted Cosine
    print("\nüîπ Model 4: CF Adjusted Cosine")
    model4 = CF_AdjustedCosine(rate_train, k=30, uuCF=1)
    model4.fit()
    rmse4 = evaluate_rmse(model4, rate_test)
    results['CF Adjusted Cosine (ri√™ng)'] = rmse4
    print(f"  RMSE = {rmse4:.4f}")
    
    # ========================================================================
    # T·ªîNG K·∫æT
    # ========================================================================
    
    print("\n" + "="*70)
    print("üèÜ T·ªîNG K·∫æT K·∫æT QU·∫¢")
    print("="*70)
    
    # Sort by RMSE
    sorted_results = sorted(results.items(), key=lambda x: x[1])
    
    print("\nüìä X·∫øp h·∫°ng theo RMSE (th·∫•p h∆°n = t·ªët h∆°n):\n")
    best_rmse = sorted_results[0][1]
    
    for idx, (method, rmse) in enumerate(sorted_results, 1):
        improvement = ((rmse4 - rmse) / rmse4) * 100  # So v·ªõi baseline
        marker = "ü•á" if idx == 1 else "ü•à" if idx == 2 else "ü•â" if idx == 3 else "  "
        print(f"{marker} {idx}. {method:30s}: RMSE = {rmse:.4f}  "
              f"(vs Baseline: {improvement:+.2f}%)")
    
    # ========================================================================
    # DEMO RECOMMENDATION
    # ========================================================================
    
    print("\n" + "="*70)
    print("üé¨ DEMO: RECOMMENDATION CHO USER")
    print("="*70)
    
    # S·ª≠ d·ª•ng ensemble model t·ªët nh·∫•t
    best_config = sorted_results[0][0]
    best_weights = weight_configs.get(best_config, [0.25, 0.25, 0.25, 0.25])
    
    print(f"\nüì¶ S·ª≠ d·ª•ng c·∫•u h√¨nh: {best_config}")
    ensemble_best = EnsembleCF(rate_train, k=30, weights=best_weights)
    ensemble_best.fit()
    
    # Recommend cho m·ªôt s·ªë users
    demo_users = [0, 10, 50, 100, 200]
    
    for user_id in demo_users:
        print(f"\nüë§ User {user_id}:")
        recommendations = ensemble_best.recommend(user_id, top_n=5)
        print(f"   Top 5 recommended items:")
        for item_id, rating in recommendations:
            print(f"      ‚Ä¢ Item {item_id}: Predicted rating = {rating:.2f}")
    
    print("\n" + "="*70)
    print("‚úÖ HO√ÄN TH√ÄNH!")
    print("="*70)
    
    print("\nüí° K·∫øt lu·∫≠n:")
    print(f"   - Model t·ªët nh·∫•t: {sorted_results[0][0]}")
    print(f"   - RMSE: {sorted_results[0][1]:.4f}")
    print(f"   - Ensemble cho k·∫øt qu·∫£ t·ªët h∆°n c√°c model ri√™ng l·∫ª!")


if __name__ == "__main__":
    main()